{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute Stocks Prices Correlation\n",
    "\n",
    "In this notebook we compute the correlation between all possible stock pairs over a moving time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a DataFrame of log returns for all stocks (calculated on Adjusted Close):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSCO</th>\n",
       "      <th>UAL</th>\n",
       "      <th>TROW</th>\n",
       "      <th>ISRG</th>\n",
       "      <th>NVR</th>\n",
       "      <th>PRGO</th>\n",
       "      <th>TPR</th>\n",
       "      <th>DVN</th>\n",
       "      <th>CE</th>\n",
       "      <th>MRO</th>\n",
       "      <th>...</th>\n",
       "      <th>CRM</th>\n",
       "      <th>PGR</th>\n",
       "      <th>WAT</th>\n",
       "      <th>IEX</th>\n",
       "      <th>BWA</th>\n",
       "      <th>LRCX</th>\n",
       "      <th>NWL</th>\n",
       "      <th>UAA</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006969</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022473</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.029852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.095310</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CSCO  UAL      TROW  ISRG       NVR  PRGO  TPR       DVN  CE  \\\n",
       "1990-01-01   NaN  NaN       NaN   NaN       NaN   NaN  NaN       NaN NaN   \n",
       "1990-01-02   NaN  NaN       NaN   NaN       NaN   NaN  NaN       NaN NaN   \n",
       "1990-01-03   NaN  NaN  0.016529   NaN  0.000000   NaN  NaN  0.018692 NaN   \n",
       "1990-01-04   NaN  NaN  0.024293   NaN  0.024098   NaN  NaN  0.000000 NaN   \n",
       "1990-01-05   NaN  NaN -0.008033   NaN  0.023530   NaN  NaN -0.018692 NaN   \n",
       "\n",
       "                 MRO  ...  CRM       PGR  WAT       IEX  BWA      LRCX  \\\n",
       "1990-01-01       NaN  ...  NaN       NaN  NaN       NaN  NaN       NaN   \n",
       "1990-01-02       NaN  ...  NaN       NaN  NaN       NaN  NaN       NaN   \n",
       "1990-01-03 -0.006969  ...  NaN  0.006472  NaN  0.000000  NaN -0.022473   \n",
       "1990-01-04  0.024182  ...  NaN -0.006472  NaN -0.029852  NaN -0.095310   \n",
       "1990-01-05 -0.013746  ...  NaN  0.003242  NaN -0.007604  NaN  0.000000   \n",
       "\n",
       "                 NWL  UAA  BLK       PPL  \n",
       "1990-01-01       NaN  NaN  NaN       NaN  \n",
       "1990-01-02       NaN  NaN  NaN       NaN  \n",
       "1990-01-03 -0.005222  NaN  NaN  0.002903  \n",
       "1990-01-04 -0.005250  NaN  NaN -0.008734  \n",
       "1990-01-05  0.000000  NaN  NaN -0.008810  \n",
       "\n",
       "[5 rows x 503 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to prices data\n",
    "path = '../data/prices/'\n",
    "\n",
    "# create empty dataframe (only business days)\n",
    "data = pd.DataFrame(index=pd.date_range(start=\"1990-01-01\", end=\"2021-01-01\", freq='B'))\n",
    "\n",
    "# iterate over files and add columns\n",
    "files = os.listdir(path)\n",
    "for file in files: \n",
    "    \n",
    "    # import, keep log returns and change column name\n",
    "    price = pd.read_csv(os.path.join(path, file), index_col=0)\n",
    "    price = price[['LogRet_AdjClose']]\n",
    "    price.columns = [file.replace('.csv', '')]\n",
    "    \n",
    "    # merge\n",
    "    data  = pd.merge(data, price, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a function to compute pairwise correlations between stocks. In particular, we consider three possible different types of correlation: \n",
    "- [Pearson](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)\n",
    "- [Kendall](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html)\n",
    "- [Spearman](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)\n",
    "\n",
    "We also have to deal with nan data. Indeed, some stocks start to be traded only after the beginning of our dataset (for example new companies), some others stop to be traded at a certain point (for example failed companies), and of course there can missing data here and there for other reasons. Therefore, we define a threshold of minimum non-nan values required in order to compute the correlation (otherwise we return a nan correlation). We note that, since we are computing pairwise correlations, we need both prices to be non-nan at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(data, ticker1, ticker2, start, end, coeff=\"pearson\", notnan_fraction=0.9):\n",
    "    \n",
    "    from scipy.stats import pearsonr, kendalltau, spearmanr\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the correlation between the prices of two stocks\n",
    "    over a given a time period:\n",
    "        :param data (pandas DataFrame): DataFrame of stocks prices\n",
    "        :param ticker1 (string): ticker of first stock\n",
    "        :param ticker2 (string): ticker of second stock\n",
    "        :param start (datetime): start of time window (included)\n",
    "        :param end (datetime): end of time window (excluded)\n",
    "        :param coeff (string, default=\"pearson\"): type of correlation (possible values: 'pearson', 'kendall', 'spearman')\n",
    "        :param notnan_fracton (float, default=0.9): fraction of non-nan prices required in order to compute correlation\n",
    "        :return: coefficient of correlation between two price series\n",
    "    \"\"\"\n",
    "    \n",
    "    # select data between start/end and get the two price time series\n",
    "    data_window = data.loc[(data.index>=start) & (data.index<end)]\n",
    "    price1 = data_window[ticker1].values\n",
    "    price2 = data_window[ticker2].values\n",
    "    \n",
    "    # control nan values: if the fraction of non-nan pairs is smaller than the parameter\n",
    "    # notnan_fraction we return a nan correlation (i.e. not enough data to compute it)\n",
    "    # We define a pair of prices a 'nan-pair' if on a day one or both of the two prices is nan\n",
    "    notnans = ~np.logical_or(np.isnan(price1), np.isnan(price2)) \n",
    "    \n",
    "    # if enough non-nan data compute correlation\n",
    "    if (notnans).sum() / len(price1) >= notnan_fraction:\n",
    "        \n",
    "        # compute correlation coefficient only on non-nan pairs (otherwise scipy raises an error)\n",
    "        if coeff==\"pearson\": \n",
    "            return pearsonr(np.compress(notnans, price1), np.compress(notnans, price2))[0]\n",
    "\n",
    "        elif coeff==\"kendall\": \n",
    "            return kendalltau(np.compress(notnans, price1), np.compress(notnans, price2))[0]\n",
    "\n",
    "        elif coeff==\"spearman\":\n",
    "            return spearmanr(np.compress(notnans, price1), np.compress(notnans, price2))[0]\n",
    "\n",
    "        else: \n",
    "            print(\"Coefficient name not recognised. Possible values: 'pearson', 'kendall', 'spearman'\")\n",
    "    \n",
    "    # not enough non-nan data, return nan correlation\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute correlation matrices (i.e matrices of correlation between all possible stocks) over a moving time frame. To keep data comparable at different time steps, we will keep rows and columns of the correlation matrix ordered like the columns of the stocks Pandas DataFrame (we save a file with the ordering in order to match row and column in next notebooks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.columns, columns=[\"ticker\"]).to_csv(\"../data/tickers_order.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the moving time frame to be 3 months long and moving forward in steps of 1 month. Let's compute the correlation matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "start = datetime(1990, 1, 1)\n",
    "end   = datetime(2021, 1, 1)\n",
    "current_date = start\n",
    "\n",
    "window = 90  # days\n",
    "step   = 30  # days\n",
    "\n",
    "tickers = data.columns.values  # list of tickers\n",
    "\n",
    "# move the time window until end of observations\n",
    "while current_date + timedelta(days=window) < end:\n",
    "    \n",
    "    # show advancement\n",
    "    print(current_date)\n",
    "    \n",
    "    # initialize correlation matrix for this frame\n",
    "    corr_matrix = np.zeros((tickers.shape[0], tickers.shape[0]))\n",
    "    \n",
    "    # iterate over tickers to compute correlations: \n",
    "    for i in range(tickers.shape[0]):\n",
    "        for j in range(tickers.shape[0]):\n",
    "            if i!=j:  # no self-correlation  \n",
    "                corr_matrix[i, j] = correlation(data, tickers[i], tickers[j], current_date, current_date + timedelta(days=window))\n",
    "                \n",
    "    # save correlation matrix\n",
    "    file_name = current_date.strftime(\"%Y%m%d\") + \"_\" + (current_date + timedelta(days=window)).strftime(\"%Y%m%d\") + \".npz\"\n",
    "    np.savez_compressed(\"../data/corr_matrices/\" + file_name, corr_matrix)\n",
    "    \n",
    "    # advance window\n",
    "    current_date += timedelta(days=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
