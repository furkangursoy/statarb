{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.stats import pearsonr, kendalltau, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute Stocks Prices Correlation\n",
    "\n",
    "In this notebook we compute the correlation between all possible stock pairs over a moving time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a DataFrame of log returns for all stocks (calculated on Adjusted Close):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8090, 648)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSCO</th>\n",
       "      <th>UAL</th>\n",
       "      <th>TROW</th>\n",
       "      <th>ISRG</th>\n",
       "      <th>NVR</th>\n",
       "      <th>PRGO</th>\n",
       "      <th>TPR</th>\n",
       "      <th>DVN</th>\n",
       "      <th>CE</th>\n",
       "      <th>MRO</th>\n",
       "      <th>...</th>\n",
       "      <th>CRM</th>\n",
       "      <th>PGR</th>\n",
       "      <th>WAT</th>\n",
       "      <th>IEX</th>\n",
       "      <th>BWA</th>\n",
       "      <th>LRCX</th>\n",
       "      <th>NWL</th>\n",
       "      <th>UAA</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006969</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022473</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024182</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.029852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.095310</td>\n",
       "      <td>-0.005250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CSCO  UAL      TROW  ISRG       NVR  PRGO  TPR       DVN  CE  \\\n",
       "1990-01-01   NaN  NaN       NaN   NaN       NaN   NaN  NaN       NaN NaN   \n",
       "1990-01-02   NaN  NaN       NaN   NaN       NaN   NaN  NaN       NaN NaN   \n",
       "1990-01-03   NaN  NaN  0.016529   NaN  0.000000   NaN  NaN  0.018692 NaN   \n",
       "1990-01-04   NaN  NaN  0.024293   NaN  0.024098   NaN  NaN  0.000000 NaN   \n",
       "1990-01-05   NaN  NaN -0.008033   NaN  0.023530   NaN  NaN -0.018692 NaN   \n",
       "\n",
       "                 MRO  ...  CRM       PGR  WAT       IEX  BWA      LRCX  \\\n",
       "1990-01-01       NaN  ...  NaN       NaN  NaN       NaN  NaN       NaN   \n",
       "1990-01-02       NaN  ...  NaN       NaN  NaN       NaN  NaN       NaN   \n",
       "1990-01-03 -0.006969  ...  NaN  0.006472  NaN  0.000000  NaN -0.022473   \n",
       "1990-01-04  0.024182  ...  NaN -0.006472  NaN -0.029852  NaN -0.095310   \n",
       "1990-01-05 -0.013746  ...  NaN  0.003242  NaN -0.007604  NaN  0.000000   \n",
       "\n",
       "                 NWL  UAA  BLK       PPL  \n",
       "1990-01-01       NaN  NaN  NaN       NaN  \n",
       "1990-01-02       NaN  NaN  NaN       NaN  \n",
       "1990-01-03 -0.005222  NaN  NaN  0.002903  \n",
       "1990-01-04 -0.005250  NaN  NaN -0.008734  \n",
       "1990-01-05  0.000000  NaN  NaN -0.008810  \n",
       "\n",
       "[5 rows x 648 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to prices data\n",
    "path = '../data/prices/'\n",
    "\n",
    "# create empty dataframe (only business days)\n",
    "data = pd.DataFrame(index=pd.date_range(start=\"1990-01-01\", end=\"2021-01-01\", freq='B'))\n",
    "\n",
    "# iterate over files and add columns\n",
    "files = os.listdir(path)\n",
    "for file in files: \n",
    "    \n",
    "    # import, keep log returns and change column name\n",
    "    price = pd.read_csv(os.path.join(path, file), index_col=0)\n",
    "    price.index = pd.to_datetime(price.index)\n",
    "    price = price[['LogRet_AdjClose']]\n",
    "    price.columns = [file.replace('.csv', '')]\n",
    "    \n",
    "    # merge\n",
    "    data  = pd.merge(data, price, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a function to compute pairwise correlations between stocks. In particular, we consider three possible different types of correlation: \n",
    "- [Pearson](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)\n",
    "- [Kendall](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html)\n",
    "- [Spearman](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)\n",
    "\n",
    "For Pearson (the default type of correlation we use), we define a fastest implementation than the one provided in $scipy$ (more details [here](https://cancerdatascience.org/blog/posts/pearson-correlation/)):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_pearson_corr(x, y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Fast implementation of Pearson correlation coefficient \n",
    "        :param x, y (numpy arrays): arrays on which we compute correlation\n",
    "        :return: returns the Pearson corr. coeff. between x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    xv, yv = x - x.mean(axis=0), y - y.mean(axis=0)\n",
    "    xvss, yvss = (xv * xv).sum(axis=0), (yv * yv).sum(axis=0)\n",
    "    result = np.matmul(xv.transpose(), yv) / np.sqrt(np.outer(xvss, yvss))\n",
    "    # bound the values to -1 to 1 in the event of precision issues\n",
    "    return np.maximum(np.minimum(result, 1.0), -1.0)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to deal with nan data. Indeed, some stocks start to be traded only after the beginning of our dataset (for example new companies), some others stop to be traded at a certain point (for example failed companies), and of course there can missing data here and there for other reasons. Therefore, we define a threshold of minimum non-nan values required in order to compute the correlation (otherwise we return a 0 correlation). We note that, since we are computing pairwise correlations, we need both prices to be non-nan at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(data_np, i, j, start, end, window, coeff=\"pearson\", notnan_fraction=0.9):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function computes the correlation between the prices of two stocks\n",
    "    over a given a time period:\n",
    "        :param data_np (numpy 2D-array): 2D-array of stocks prices\n",
    "        :param i (int): index of ticker of first stock\n",
    "        :param j (int): index of ticker of second stock\n",
    "        :param start (int): start of time window (included)\n",
    "        :param end (int): end of time window (excluded)\n",
    "        :param coeff (string, default=\"pearson\"): type of correlation (possible values: 'pearson', 'kendall', 'spearman')\n",
    "        :param notnan_fracton (float, default=0.9): fraction of non-nan prices required in order to compute correlation\n",
    "        :return: coefficient of correlation between two price series\n",
    "    \"\"\"\n",
    "    \n",
    "    # select data between start/end and get the two price time series\n",
    "    price1 = data_np[start:end, i]\n",
    "    price2 = data_np[start:end, j]\n",
    "    \n",
    "    # control nan values: if the fraction of non-nan pairs is smaller than the parameter\n",
    "    # notnan_fraction we return a nan correlation (i.e. not enough data to compute it)\n",
    "    # We define a pair of prices a 'nan-pair' if on a day one or both of the two prices is nan\n",
    "    notnans = ~np.logical_or(np.isnan(price1), np.isnan(price2))\n",
    "    \n",
    "    # if enough non-nan data compute correlation\n",
    "    if (notnans).sum() / window >= notnan_fraction:\n",
    "        \n",
    "        # compute correlation coefficient only on non-nan pairs (otherwise scipy raises an error)\n",
    "        if coeff==\"pearson\": \n",
    "            return np_pearson_corr(np.compress(notnans, price1), np.compress(notnans, price2))\n",
    "\n",
    "        elif coeff==\"kendall\": \n",
    "            return kendalltau(np.compress(notnans, price1), np.compress(notnans, price2))[0]\n",
    "\n",
    "        elif coeff==\"spearman\":\n",
    "            return spearmanr(np.compress(notnans, price1), np.compress(notnans, price2))[0]\n",
    "\n",
    "        else: \n",
    "            print(\"Coefficient name not recognised. Possible values: 'pearson', 'kendall', 'spearman'\")\n",
    "    \n",
    "    # not enough non-nan data, return 0 correlation\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute correlation matrices (i.e matrices of correlation between all possible stocks) over a moving time frame. To keep data comparable at different time steps, we will keep rows and columns of the correlation matrix ordered like the columns of the stocks Pandas DataFrame (we save a file with the ordering in order to match row and column in next notebooks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.columns, columns=[\"ticker\"]).to_csv(\"../data/tickers_order.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the moving time frame to be 3 months long and moving forward in steps of 1 month. Let's compute the correlation matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-09 00:00:00\n",
      "2020-07-17 00:00:00\n",
      "2020-04-24 00:00:00\n",
      "2020-01-31 00:00:00\n",
      "2019-11-08 00:00:00\n",
      "2019-08-16 00:00:00\n",
      "2019-05-24 00:00:00\n",
      "2019-03-01 00:00:00\n",
      "2018-12-07 00:00:00\n",
      "2018-09-14 00:00:00\n",
      "2018-06-22 00:00:00\n",
      "2018-03-30 00:00:00\n",
      "2018-01-05 00:00:00\n",
      "2017-10-13 00:00:00\n",
      "2017-07-21 00:00:00\n",
      "2017-04-28 00:00:00\n",
      "2017-02-03 00:00:00\n",
      "2016-11-11 00:00:00\n",
      "2016-08-19 00:00:00\n",
      "2016-05-27 00:00:00\n",
      "2016-03-04 00:00:00\n",
      "2015-12-11 00:00:00\n",
      "2015-09-18 00:00:00\n",
      "2015-06-26 00:00:00\n",
      "2015-04-03 00:00:00\n",
      "2015-01-09 00:00:00\n",
      "2014-10-17 00:00:00\n",
      "2014-07-25 00:00:00\n",
      "2014-05-02 00:00:00\n",
      "2014-02-07 00:00:00\n",
      "2013-11-15 00:00:00\n",
      "2013-08-23 00:00:00\n",
      "2013-05-31 00:00:00\n",
      "2013-03-08 00:00:00\n",
      "2012-12-14 00:00:00\n",
      "2012-09-21 00:00:00\n",
      "2012-06-29 00:00:00\n",
      "2012-04-06 00:00:00\n",
      "2012-01-13 00:00:00\n",
      "2011-10-21 00:00:00\n",
      "2011-07-29 00:00:00\n",
      "2011-05-06 00:00:00\n",
      "2011-02-11 00:00:00\n",
      "2010-11-19 00:00:00\n",
      "2010-08-27 00:00:00\n",
      "2010-06-04 00:00:00\n",
      "2010-03-12 00:00:00\n",
      "2009-12-18 00:00:00\n",
      "2009-09-25 00:00:00\n",
      "2009-07-03 00:00:00\n",
      "2009-04-10 00:00:00\n",
      "2009-01-16 00:00:00\n",
      "2008-10-24 00:00:00\n",
      "2008-08-01 00:00:00\n",
      "2008-05-09 00:00:00\n",
      "2008-02-15 00:00:00\n",
      "2007-11-23 00:00:00\n",
      "2007-08-31 00:00:00\n",
      "2007-06-08 00:00:00\n",
      "2007-03-16 00:00:00\n",
      "2006-12-22 00:00:00\n",
      "2006-09-29 00:00:00\n",
      "2006-07-07 00:00:00\n",
      "2006-04-14 00:00:00\n",
      "2006-01-20 00:00:00\n",
      "2005-10-28 00:00:00\n",
      "2005-08-05 00:00:00\n",
      "2005-05-13 00:00:00\n",
      "2005-02-18 00:00:00\n",
      "2004-11-26 00:00:00\n",
      "2004-09-03 00:00:00\n",
      "2004-06-11 00:00:00\n",
      "2004-03-19 00:00:00\n",
      "2003-12-26 00:00:00\n",
      "2003-10-03 00:00:00\n",
      "2003-07-11 00:00:00\n",
      "2003-04-18 00:00:00\n",
      "2003-01-24 00:00:00\n",
      "2002-11-01 00:00:00\n",
      "2002-08-09 00:00:00\n",
      "2002-05-17 00:00:00\n",
      "2002-02-22 00:00:00\n",
      "2001-11-30 00:00:00\n",
      "2001-09-07 00:00:00\n",
      "2001-06-15 00:00:00\n",
      "2001-03-23 00:00:00\n",
      "2000-12-29 00:00:00\n",
      "2000-10-06 00:00:00\n",
      "2000-07-14 00:00:00\n",
      "2000-04-21 00:00:00\n",
      "2000-01-28 00:00:00\n",
      "1999-11-05 00:00:00\n",
      "1999-08-13 00:00:00\n",
      "1999-05-21 00:00:00\n",
      "1999-02-26 00:00:00\n",
      "1998-12-04 00:00:00\n",
      "1998-09-11 00:00:00\n",
      "1998-06-19 00:00:00\n",
      "1998-03-27 00:00:00\n",
      "1998-01-02 00:00:00\n",
      "1997-10-10 00:00:00\n",
      "1997-07-18 00:00:00\n",
      "1997-04-25 00:00:00\n",
      "1997-01-31 00:00:00\n",
      "1996-11-08 00:00:00\n",
      "1996-08-16 00:00:00\n",
      "1996-05-24 00:00:00\n",
      "1996-03-01 00:00:00\n",
      "1995-12-08 00:00:00\n",
      "1995-09-15 00:00:00\n",
      "1995-06-23 00:00:00\n",
      "1995-03-31 00:00:00\n",
      "1995-01-06 00:00:00\n",
      "1994-10-14 00:00:00\n",
      "1994-07-22 00:00:00\n",
      "1994-04-29 00:00:00\n",
      "1994-02-04 00:00:00\n",
      "1993-11-12 00:00:00\n",
      "1993-08-20 00:00:00\n",
      "1993-05-28 00:00:00\n",
      "1993-03-05 00:00:00\n",
      "1992-12-11 00:00:00\n",
      "1992-09-18 00:00:00\n",
      "1992-06-26 00:00:00\n",
      "1992-04-03 00:00:00\n",
      "1992-01-10 00:00:00\n",
      "1991-10-18 00:00:00\n",
      "1991-07-26 00:00:00\n",
      "1991-05-03 00:00:00\n",
      "1991-02-08 00:00:00\n",
      "1990-11-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# list of tickers\n",
    "tickers = data.columns.values  \n",
    "\n",
    "# numpy version of DataFrame (faster)\n",
    "data_np = data.to_numpy()\n",
    "\n",
    "start = data_np.shape[0]\n",
    "end   = 0 \n",
    "current_step = start\n",
    "\n",
    "# datetimes\n",
    "current_date = data.index[-1]\n",
    "\n",
    "window = 180  # days\n",
    "step   = 60  # days\n",
    "\n",
    "# move the time window until end of observations\n",
    "while current_step - window >= end:\n",
    "    \n",
    "    # show advancement\n",
    "    print(data.index[current_step-1])\n",
    "    \n",
    "    # initialize correlation matrix for this frame\n",
    "    corr_matrix = np.zeros((tickers.shape[0], tickers.shape[0]), dtype=np.float16)\n",
    "    \n",
    "    # iterate over tickers to compute correlations\n",
    "    for i in range(tickers.shape[0]):\n",
    "        for j in range(tickers.shape[0]):\n",
    "            if i > j:  # no self-correlation and matrix is symmetric\n",
    "                corr_matrix[i, j] = correlation(data_np, i, j, current_step - window, current_step, window)\n",
    "                \n",
    "    # save correlation matrix\n",
    "    file_name = current_date.strftime(\"%Y%m%d\") + \"_\" + (current_date - timedelta(days=window)).strftime(\"%Y%m%d\") + \".npz\"\n",
    "    np.savez_compressed(\"../data/corr_matrices/\" + file_name, corr_matrix)\n",
    "\n",
    "    # advance window\n",
    "    current_step -= step\n",
    "    current_date = data.index[current_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
